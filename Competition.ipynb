{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OCV1K0L-85-KGCjnMZsoAEYWu3KNgw6h",
      "authorship_tag": "ABX9TyMLvGjvp9DsfJsv49298Tpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bajajraj/FinancialDataAnalysis/blob/main/Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N9MXZ1ZDgnhl"
      },
      "outputs": [],
      "source": [
        "# importing modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store x_train in Dataframe\n",
        "x_train = pd.read_csv('x_train.csv')\n",
        "print(\"The shape of the x_train is\", x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjOK4wCXg0oA",
        "outputId": "0161adfa-6884-4d8e-fb13-f31dc0281b5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the x_train is (200000, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the y_train in Datframe\n",
        "y_train = pd.read_csv('y_train.csv')\n",
        "print(\"The shape of the y_train is\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5l1OjqWhODq",
        "outputId": "a340b1a7-c495-4a5f-e4f5-1d0f787243d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the y_train is (200000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the x_test in DataFrame\n",
        "x_test = pd.read_csv('x_test.csv')\n",
        "print('The shape of the x_test is', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayccPkURhRBW",
        "outputId": "b62326c8-16a9-4cc3-a367-18a6c3ac1123"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the x_test is (10000, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing some data preprocessing. First, converting the data for normalization using Min-Max Scaling between the range of 0\n",
        "# to 1\n",
        "\n",
        "# Create MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "# apply Min-Max scaling to all columns\n",
        "x_normalized_data = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
        "x_normalized_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pqEjviVhhTJ8",
        "outputId": "9af70698-c056-43a0-90f7-abc8465fd88d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              v1        v2        v3        v4        v5        v6        v7  \\\n",
              "0       0.013166  0.768603  0.266142  0.535434  0.522835  0.541423  0.783392   \n",
              "1       0.000228  0.801162  0.242514  0.555572  0.538073  0.549635  0.787447   \n",
              "2       0.031874  0.817670  0.400953  0.527333  0.587932  0.534521  0.793047   \n",
              "3       0.006867  0.818750  0.186868  0.541694  0.535038  0.542487  0.784022   \n",
              "4       0.002747  0.817387  0.261164  0.552048  0.543797  0.550565  0.785926   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "199995  0.001567  0.786132  0.295686  0.568267  0.629324  0.531030  0.803605   \n",
              "199996  0.007326  0.798893  0.301278  0.542977  0.549272  0.538444  0.786754   \n",
              "199997  0.001272  0.793069  0.157386  0.553693  0.522448  0.551939  0.782272   \n",
              "199998  0.000544  0.763356  0.170194  0.532351  0.521483  0.534035  0.797997   \n",
              "199999  0.001475  0.797104  0.193456  0.537817  0.515131  0.545389  0.794162   \n",
              "\n",
              "              v8        v9       v10  ...       v18       v19       v20  \\\n",
              "0       0.501795  0.502335  0.268482  ...  0.544884  0.395308  0.561678   \n",
              "1       0.457165  0.497903  0.234985  ...  0.558398  0.390898  0.556413   \n",
              "2       0.490613  0.509299  0.335463  ...  0.471219  0.406263  0.570319   \n",
              "3       0.441919  0.521529  0.395007  ...  0.536447  0.381165  0.566132   \n",
              "4       0.441782  0.501923  0.251173  ...  0.650606  0.391680  0.556455   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "199995  0.446723  0.515637  0.236953  ...  0.539218  0.385381  0.561330   \n",
              "199996  0.474722  0.505937  0.253219  ...  0.501090  0.393688  0.564249   \n",
              "199997  0.405393  0.507627  0.253134  ...  0.592491  0.393279  0.569585   \n",
              "199998  0.472407  0.488551  0.327849  ...  0.732113  0.383653  0.564374   \n",
              "199999  0.438626  0.493937  0.381195  ...  0.533268  0.389630  0.560591   \n",
              "\n",
              "             v21       v22       v23       v24       v25       v26       v27  \n",
              "0       0.491362  0.704808  0.411224  0.543566  0.395226  0.648976  0.257249  \n",
              "1       0.470343  0.700732  0.265424  0.570273  0.475939  0.657261  0.258859  \n",
              "2       0.541971  0.692552  0.386553  0.581683  0.485832  0.650151  0.259935  \n",
              "3       0.586573  0.715858  0.419549  0.571692  0.405871  0.651065  0.248055  \n",
              "4       0.465054  0.700437  0.299797  0.572812  0.508024  0.648075  0.258368  \n",
              "...          ...       ...       ...       ...       ...       ...       ...  \n",
              "199995  0.500019  0.703333  0.557150  0.578470  0.423333  0.625833  0.249951  \n",
              "199996  0.524623  0.698836  0.305282  0.598338  0.396082  0.651660  0.258256  \n",
              "199997  0.573206  0.695802  0.522766  0.601414  0.453475  0.651952  0.259701  \n",
              "199998  0.503341  0.702928  0.365480  0.550635  0.409866  0.607199  0.249779  \n",
              "199999  0.495147  0.703649  0.496610  0.563382  0.556007  0.653195  0.259131  \n",
              "\n",
              "[200000 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-006c732b-02cd-47d2-8d08-95291a70e265\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>...</th>\n",
              "      <th>v18</th>\n",
              "      <th>v19</th>\n",
              "      <th>v20</th>\n",
              "      <th>v21</th>\n",
              "      <th>v22</th>\n",
              "      <th>v23</th>\n",
              "      <th>v24</th>\n",
              "      <th>v25</th>\n",
              "      <th>v26</th>\n",
              "      <th>v27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013166</td>\n",
              "      <td>0.768603</td>\n",
              "      <td>0.266142</td>\n",
              "      <td>0.535434</td>\n",
              "      <td>0.522835</td>\n",
              "      <td>0.541423</td>\n",
              "      <td>0.783392</td>\n",
              "      <td>0.501795</td>\n",
              "      <td>0.502335</td>\n",
              "      <td>0.268482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.544884</td>\n",
              "      <td>0.395308</td>\n",
              "      <td>0.561678</td>\n",
              "      <td>0.491362</td>\n",
              "      <td>0.704808</td>\n",
              "      <td>0.411224</td>\n",
              "      <td>0.543566</td>\n",
              "      <td>0.395226</td>\n",
              "      <td>0.648976</td>\n",
              "      <td>0.257249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.801162</td>\n",
              "      <td>0.242514</td>\n",
              "      <td>0.555572</td>\n",
              "      <td>0.538073</td>\n",
              "      <td>0.549635</td>\n",
              "      <td>0.787447</td>\n",
              "      <td>0.457165</td>\n",
              "      <td>0.497903</td>\n",
              "      <td>0.234985</td>\n",
              "      <td>...</td>\n",
              "      <td>0.558398</td>\n",
              "      <td>0.390898</td>\n",
              "      <td>0.556413</td>\n",
              "      <td>0.470343</td>\n",
              "      <td>0.700732</td>\n",
              "      <td>0.265424</td>\n",
              "      <td>0.570273</td>\n",
              "      <td>0.475939</td>\n",
              "      <td>0.657261</td>\n",
              "      <td>0.258859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.031874</td>\n",
              "      <td>0.817670</td>\n",
              "      <td>0.400953</td>\n",
              "      <td>0.527333</td>\n",
              "      <td>0.587932</td>\n",
              "      <td>0.534521</td>\n",
              "      <td>0.793047</td>\n",
              "      <td>0.490613</td>\n",
              "      <td>0.509299</td>\n",
              "      <td>0.335463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.471219</td>\n",
              "      <td>0.406263</td>\n",
              "      <td>0.570319</td>\n",
              "      <td>0.541971</td>\n",
              "      <td>0.692552</td>\n",
              "      <td>0.386553</td>\n",
              "      <td>0.581683</td>\n",
              "      <td>0.485832</td>\n",
              "      <td>0.650151</td>\n",
              "      <td>0.259935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.006867</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.186868</td>\n",
              "      <td>0.541694</td>\n",
              "      <td>0.535038</td>\n",
              "      <td>0.542487</td>\n",
              "      <td>0.784022</td>\n",
              "      <td>0.441919</td>\n",
              "      <td>0.521529</td>\n",
              "      <td>0.395007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.536447</td>\n",
              "      <td>0.381165</td>\n",
              "      <td>0.566132</td>\n",
              "      <td>0.586573</td>\n",
              "      <td>0.715858</td>\n",
              "      <td>0.419549</td>\n",
              "      <td>0.571692</td>\n",
              "      <td>0.405871</td>\n",
              "      <td>0.651065</td>\n",
              "      <td>0.248055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002747</td>\n",
              "      <td>0.817387</td>\n",
              "      <td>0.261164</td>\n",
              "      <td>0.552048</td>\n",
              "      <td>0.543797</td>\n",
              "      <td>0.550565</td>\n",
              "      <td>0.785926</td>\n",
              "      <td>0.441782</td>\n",
              "      <td>0.501923</td>\n",
              "      <td>0.251173</td>\n",
              "      <td>...</td>\n",
              "      <td>0.650606</td>\n",
              "      <td>0.391680</td>\n",
              "      <td>0.556455</td>\n",
              "      <td>0.465054</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.299797</td>\n",
              "      <td>0.572812</td>\n",
              "      <td>0.508024</td>\n",
              "      <td>0.648075</td>\n",
              "      <td>0.258368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.786132</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>0.568267</td>\n",
              "      <td>0.629324</td>\n",
              "      <td>0.531030</td>\n",
              "      <td>0.803605</td>\n",
              "      <td>0.446723</td>\n",
              "      <td>0.515637</td>\n",
              "      <td>0.236953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.539218</td>\n",
              "      <td>0.385381</td>\n",
              "      <td>0.561330</td>\n",
              "      <td>0.500019</td>\n",
              "      <td>0.703333</td>\n",
              "      <td>0.557150</td>\n",
              "      <td>0.578470</td>\n",
              "      <td>0.423333</td>\n",
              "      <td>0.625833</td>\n",
              "      <td>0.249951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>0.007326</td>\n",
              "      <td>0.798893</td>\n",
              "      <td>0.301278</td>\n",
              "      <td>0.542977</td>\n",
              "      <td>0.549272</td>\n",
              "      <td>0.538444</td>\n",
              "      <td>0.786754</td>\n",
              "      <td>0.474722</td>\n",
              "      <td>0.505937</td>\n",
              "      <td>0.253219</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501090</td>\n",
              "      <td>0.393688</td>\n",
              "      <td>0.564249</td>\n",
              "      <td>0.524623</td>\n",
              "      <td>0.698836</td>\n",
              "      <td>0.305282</td>\n",
              "      <td>0.598338</td>\n",
              "      <td>0.396082</td>\n",
              "      <td>0.651660</td>\n",
              "      <td>0.258256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>0.001272</td>\n",
              "      <td>0.793069</td>\n",
              "      <td>0.157386</td>\n",
              "      <td>0.553693</td>\n",
              "      <td>0.522448</td>\n",
              "      <td>0.551939</td>\n",
              "      <td>0.782272</td>\n",
              "      <td>0.405393</td>\n",
              "      <td>0.507627</td>\n",
              "      <td>0.253134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.592491</td>\n",
              "      <td>0.393279</td>\n",
              "      <td>0.569585</td>\n",
              "      <td>0.573206</td>\n",
              "      <td>0.695802</td>\n",
              "      <td>0.522766</td>\n",
              "      <td>0.601414</td>\n",
              "      <td>0.453475</td>\n",
              "      <td>0.651952</td>\n",
              "      <td>0.259701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.763356</td>\n",
              "      <td>0.170194</td>\n",
              "      <td>0.532351</td>\n",
              "      <td>0.521483</td>\n",
              "      <td>0.534035</td>\n",
              "      <td>0.797997</td>\n",
              "      <td>0.472407</td>\n",
              "      <td>0.488551</td>\n",
              "      <td>0.327849</td>\n",
              "      <td>...</td>\n",
              "      <td>0.732113</td>\n",
              "      <td>0.383653</td>\n",
              "      <td>0.564374</td>\n",
              "      <td>0.503341</td>\n",
              "      <td>0.702928</td>\n",
              "      <td>0.365480</td>\n",
              "      <td>0.550635</td>\n",
              "      <td>0.409866</td>\n",
              "      <td>0.607199</td>\n",
              "      <td>0.249779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.797104</td>\n",
              "      <td>0.193456</td>\n",
              "      <td>0.537817</td>\n",
              "      <td>0.515131</td>\n",
              "      <td>0.545389</td>\n",
              "      <td>0.794162</td>\n",
              "      <td>0.438626</td>\n",
              "      <td>0.493937</td>\n",
              "      <td>0.381195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533268</td>\n",
              "      <td>0.389630</td>\n",
              "      <td>0.560591</td>\n",
              "      <td>0.495147</td>\n",
              "      <td>0.703649</td>\n",
              "      <td>0.496610</td>\n",
              "      <td>0.563382</td>\n",
              "      <td>0.556007</td>\n",
              "      <td>0.653195</td>\n",
              "      <td>0.259131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-006c732b-02cd-47d2-8d08-95291a70e265')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-006c732b-02cd-47d2-8d08-95291a70e265 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-006c732b-02cd-47d2-8d08-95291a70e265');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating some plot to see the data seperation\n",
        "# separate 0 and 1 values into two Series\n",
        "zeros = y_train.loc[y_train['isfraud'] == 0, 'isfraud']\n",
        "ones = y_train.loc[y_train['isfraud'] == 1, 'isfraud']\n",
        "\n",
        "# create scatter plots for 0 and 1 values\n",
        "plt.scatter(range(len(zeros)), zeros, color='blue', marker='o', label='0')\n",
        "plt.scatter(range(len(ones)), ones, color='red', marker='x', label='1')\n",
        "\n",
        "# add axis labels and legend\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ZYVOjyKGhU-L",
        "outputId": "5635890b-c6a2-4068-e1ac-7b82bf00531d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now it can be seen that there are much more of 0s than 1s in our data, so it best to reduce the number of 0s to not\n",
        "# have a bias machine learning training data.\n",
        "\n",
        "# Let us first look at the number of 0s and 1s\n",
        "print('The number of 0s are', len(zeros))\n",
        "print('The number of 1s are', len(ones))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbkByx3DhWgs",
        "outputId": "9c4e3f22-8a3c-4950-8498-3c59518a15d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of 0s are 199647\n",
            "The number of 1s are 353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is best to make the data balance. I will be using the Synthetic minority over-sampling technique. It will allow\n",
        "# to handle class imbalance. It involves generating synthetic samples for minority class using interpolation. \n",
        "\n",
        "# perform SMOTE over-sampling\n",
        "smote = SMOTE()\n",
        "x_resampled, y_resampled = smote.fit_resample(x_normalized_data, y_train)\n",
        "\n",
        "# print the number of samples in each class\n",
        "print('The shape of features is', x_resampled.shape)\n",
        "print('The shape of label is', y_resampled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW6rhzsphYU0",
        "outputId": "95cdb3c0-0ecf-4695-c462-c40fabf1d29a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of features is (399294, 27)\n",
            "The shape of label is (399294, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us now look at the samples and see the visualization\n",
        "# Creating some plot to see the data seperation\n",
        "# separate 0 and 1 values into two Series\n",
        "zeros = y_resampled.loc[y_resampled['isfraud'] == 0, 'isfraud']\n",
        "ones = y_resampled.loc[y_resampled['isfraud'] == 1, 'isfraud']\n",
        "\n",
        "# create scatter plots for 0 and 1 values\n",
        "plt.scatter(range(len(zeros)), zeros, color='blue', marker='o', label='0')\n",
        "plt.scatter(range(len(ones)), ones, color='red', marker='x', label='1')\n",
        "\n",
        "# add axis labels and legend\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend()\n",
        "\n",
        "# show plot\n",
        "plt.show()\n",
        "print('The number of 0s in the new balanced data is', len(zeros))\n",
        "print('The number of 1s in the new balanced data is', len(ones))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "VYhxzZ3khbFQ",
        "outputId": "105b2e4c-3c45-411f-c0eb-baee89e50e2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of 0s in the new balanced data is 199647\n",
            "The number of 1s in the new balanced data is 199647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain = x_resampled.to_numpy()\n",
        "ytrain = y_resampled.to_numpy()\n",
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYi6OyshcuY",
        "outputId": "87692070-d22c-47bb-b9e8-ba9b97418e88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(399294, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_pipeline = Pipeline([(\"logreg\", LogisticRegression(solver = 'liblinear', \n",
        "                                                                       random_state = 42, max_iter=400, \n",
        "                                                                        class_weight='balanced'))])"
      ],
      "metadata": {
        "id": "0M4IiHvjheZK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_pipeline.fit(xtrain, np.ravel(ytrain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsLCxkffhgUf",
        "outputId": "51e50e40-53fb-4e9f-87e9-d4ff1e12e707"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('logreg',\n",
              "                 LogisticRegression(class_weight='balanced', max_iter=400,\n",
              "                                    random_state=42, solver='liblinear'))])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_split_train_test(features, label, train_perc=.8, random_state=42):\n",
        "    \"\"\"\n",
        "    Shuffle the features and labels so they are in a random order.\n",
        "        sklearn.utils.shuffle does this well.\n",
        "    Then split the features and labels into training and testing sets\n",
        "        where train_perc of the samples are in training and the\n",
        "        remaining are for testing.\n",
        "    \"\"\"\n",
        "    #features_shuffles, label_shuffle = shuffle(features, label, random_state=42)\n",
        "    test_size = 1 - train_perc\n",
        "    features_tr, features_te, label_tr, label_te = train_test_split(features, label, \n",
        "                                                                     train_size=train_perc,\n",
        "                                                                     shuffle=True,\n",
        "                                                                     random_state=random_state,\n",
        "                                                                     stratify=label)\n",
        "    \n",
        "    return features_tr, features_te, label_tr, label_te"
      ],
      "metadata": {
        "id": "VYdP06RChiOp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_tr, features_te, label_tr, label_te = rand_split_train_test(xtrain, ytrain)"
      ],
      "metadata": {
        "id": "_2v5NvdFhjkF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_train_logistic_regression = logistic_regression_pipeline.predict(features_te)"
      ],
      "metadata": {
        "id": "sWhYT9CwhlFY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_log = accuracy_score(label_te, predicted_train_logistic_regression)"
      ],
      "metadata": {
        "id": "VnfvQt6OhmgH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAs5a7Yahnv_",
        "outputId": "ae748837-e0ac-4251-92a3-8bb184cc65d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.939430746691043"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(label_te, predicted_train_logistic_regression))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXHgW3NAhpEC",
        "outputId": "3c1ed8f8-877d-4647-b56b-6b42925f39c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94     39930\n",
            "           1       0.97      0.90      0.94     39929\n",
            "\n",
            "    accuracy                           0.94     79859\n",
            "   macro avg       0.94      0.94      0.94     79859\n",
            "weighted avg       0.94      0.94      0.94     79859\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(label_te, predicted_train_logistic_regression))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBy6K_5Thqz5",
        "outputId": "57e41b77-2ac1-47ed-8565-6b0540d47837"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8810348804008525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJfv4cP2h8LW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}