{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OCV1K0L-85-KGCjnMZsoAEYWu3KNgw6h",
      "authorship_tag": "ABX9TyMUGd5yD17t6VuSL8k5YRQY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bajajraj/FinancialDataAnalysis/blob/main/ytestPrediction_BajajRajaditya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FI 824 Competition\n",
        "**Raj Bajaj**\n",
        "\n",
        "This code is part of the competition for FI 824 class written by Raj Bajaj. It is used for detecting the fraud for the given test data. The steps for the algorithm is - \n",
        "\n",
        "1.) First all the data is loaded in the required format.\n",
        "\n",
        "2.) Then the training and testing features are normalized using between the range of 0 and 1 using Min-Max Scaling.\n",
        "\n",
        "3.) After normalizing the data, a graph visulization is made to look how much the data is imbalanced.\n",
        "\n",
        "4.) It was seen that the data was too imbalanced, then Synthetic minority over-sampling technique was used which involves generating synthetic samples for minority class using interpolation. \n",
        "\n",
        "5) After that, the data is splitted into 80% for training and 20% for testing to see the accuracy.\n",
        "\n",
        "6) If the current model passes, it is then trained on the whole data for the predicting on the test features provided.\n",
        "\n",
        "7) In the end, test features are loaded."
      ],
      "metadata": {
        "id": "jb0jFjsbt6SH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "N9MXZ1ZDgnhl"
      },
      "outputs": [],
      "source": [
        "# importing modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store x_train in Dataframe\n",
        "df_xtrain = pd.read_csv('x_train.csv')\n",
        "print(\"The shape of the x_train is\", df_xtrain.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjOK4wCXg0oA",
        "outputId": "2358ce86-341c-4188-8da9-80719c54eb45"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the x_train is (200000, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the y_train in Datframe\n",
        "df_ytrain = pd.read_csv('y_train.csv')\n",
        "print(\"The shape of the y_train is\", df_ytrain.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5l1OjqWhODq",
        "outputId": "1eef8252-0b60-4228-8964-a08e42825ed8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the y_train is (200000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the x_test in DataFrame\n",
        "df_xtest = pd.read_csv('x_test.csv')\n",
        "print('The shape of the x_test is', df_xtest.shape)\n",
        "xtest_id = df_xtest.iloc[:,0].to_numpy()\n",
        "xtest_id = xtest_id.reshape((xtest_id.shape[0],1))\n",
        "df_xtest = df_xtest.iloc[:,1:]\n",
        "print('The shape of the xtest after removing the id column is', df_xtest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayccPkURhRBW",
        "outputId": "5f308698-4045-4fd0-a3a5-5d0d6ba08558"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the x_test is (10000, 28)\n",
            "The shape of the xtest after removing the id column is (10000, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing some data preprocessing. First, converting the data for normalization using Min-Max Scaling between the range of 0\n",
        "# to 1\n",
        "\n",
        "# Create MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "# apply Min-Max scaling to all columns\n",
        "x_normalized_data = pd.DataFrame(scaler.fit_transform(df_xtrain), columns=df_xtrain.columns)\n",
        "x_normalized_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pqEjviVhhTJ8",
        "outputId": "cb7cd464-ad49-4658-cca4-997148b460f5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              v1        v2        v3        v4        v5        v6        v7  \\\n",
              "0       0.013166  0.768603  0.266142  0.535434  0.522835  0.541423  0.783392   \n",
              "1       0.000228  0.801162  0.242514  0.555572  0.538073  0.549635  0.787447   \n",
              "2       0.031874  0.817670  0.400953  0.527333  0.587932  0.534521  0.793047   \n",
              "3       0.006867  0.818750  0.186868  0.541694  0.535038  0.542487  0.784022   \n",
              "4       0.002747  0.817387  0.261164  0.552048  0.543797  0.550565  0.785926   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "199995  0.001567  0.786132  0.295686  0.568267  0.629324  0.531030  0.803605   \n",
              "199996  0.007326  0.798893  0.301278  0.542977  0.549272  0.538444  0.786754   \n",
              "199997  0.001272  0.793069  0.157386  0.553693  0.522448  0.551939  0.782272   \n",
              "199998  0.000544  0.763356  0.170194  0.532351  0.521483  0.534035  0.797997   \n",
              "199999  0.001475  0.797104  0.193456  0.537817  0.515131  0.545389  0.794162   \n",
              "\n",
              "              v8        v9       v10  ...       v18       v19       v20  \\\n",
              "0       0.501795  0.502335  0.268482  ...  0.544884  0.395308  0.561678   \n",
              "1       0.457165  0.497903  0.234985  ...  0.558398  0.390898  0.556413   \n",
              "2       0.490613  0.509299  0.335463  ...  0.471219  0.406263  0.570319   \n",
              "3       0.441919  0.521529  0.395007  ...  0.536447  0.381165  0.566132   \n",
              "4       0.441782  0.501923  0.251173  ...  0.650606  0.391680  0.556455   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "199995  0.446723  0.515637  0.236953  ...  0.539218  0.385381  0.561330   \n",
              "199996  0.474722  0.505937  0.253219  ...  0.501090  0.393688  0.564249   \n",
              "199997  0.405393  0.507627  0.253134  ...  0.592491  0.393279  0.569585   \n",
              "199998  0.472407  0.488551  0.327849  ...  0.732113  0.383653  0.564374   \n",
              "199999  0.438626  0.493937  0.381195  ...  0.533268  0.389630  0.560591   \n",
              "\n",
              "             v21       v22       v23       v24       v25       v26       v27  \n",
              "0       0.491362  0.704808  0.411224  0.543566  0.395226  0.648976  0.257249  \n",
              "1       0.470343  0.700732  0.265424  0.570273  0.475939  0.657261  0.258859  \n",
              "2       0.541971  0.692552  0.386553  0.581683  0.485832  0.650151  0.259935  \n",
              "3       0.586573  0.715858  0.419549  0.571692  0.405871  0.651065  0.248055  \n",
              "4       0.465054  0.700437  0.299797  0.572812  0.508024  0.648075  0.258368  \n",
              "...          ...       ...       ...       ...       ...       ...       ...  \n",
              "199995  0.500019  0.703333  0.557150  0.578470  0.423333  0.625833  0.249951  \n",
              "199996  0.524623  0.698836  0.305282  0.598338  0.396082  0.651660  0.258256  \n",
              "199997  0.573206  0.695802  0.522766  0.601414  0.453475  0.651952  0.259701  \n",
              "199998  0.503341  0.702928  0.365480  0.550635  0.409866  0.607199  0.249779  \n",
              "199999  0.495147  0.703649  0.496610  0.563382  0.556007  0.653195  0.259131  \n",
              "\n",
              "[200000 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af9a2ded-ac91-4f82-a20e-932f663a33ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>...</th>\n",
              "      <th>v18</th>\n",
              "      <th>v19</th>\n",
              "      <th>v20</th>\n",
              "      <th>v21</th>\n",
              "      <th>v22</th>\n",
              "      <th>v23</th>\n",
              "      <th>v24</th>\n",
              "      <th>v25</th>\n",
              "      <th>v26</th>\n",
              "      <th>v27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013166</td>\n",
              "      <td>0.768603</td>\n",
              "      <td>0.266142</td>\n",
              "      <td>0.535434</td>\n",
              "      <td>0.522835</td>\n",
              "      <td>0.541423</td>\n",
              "      <td>0.783392</td>\n",
              "      <td>0.501795</td>\n",
              "      <td>0.502335</td>\n",
              "      <td>0.268482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.544884</td>\n",
              "      <td>0.395308</td>\n",
              "      <td>0.561678</td>\n",
              "      <td>0.491362</td>\n",
              "      <td>0.704808</td>\n",
              "      <td>0.411224</td>\n",
              "      <td>0.543566</td>\n",
              "      <td>0.395226</td>\n",
              "      <td>0.648976</td>\n",
              "      <td>0.257249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.801162</td>\n",
              "      <td>0.242514</td>\n",
              "      <td>0.555572</td>\n",
              "      <td>0.538073</td>\n",
              "      <td>0.549635</td>\n",
              "      <td>0.787447</td>\n",
              "      <td>0.457165</td>\n",
              "      <td>0.497903</td>\n",
              "      <td>0.234985</td>\n",
              "      <td>...</td>\n",
              "      <td>0.558398</td>\n",
              "      <td>0.390898</td>\n",
              "      <td>0.556413</td>\n",
              "      <td>0.470343</td>\n",
              "      <td>0.700732</td>\n",
              "      <td>0.265424</td>\n",
              "      <td>0.570273</td>\n",
              "      <td>0.475939</td>\n",
              "      <td>0.657261</td>\n",
              "      <td>0.258859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.031874</td>\n",
              "      <td>0.817670</td>\n",
              "      <td>0.400953</td>\n",
              "      <td>0.527333</td>\n",
              "      <td>0.587932</td>\n",
              "      <td>0.534521</td>\n",
              "      <td>0.793047</td>\n",
              "      <td>0.490613</td>\n",
              "      <td>0.509299</td>\n",
              "      <td>0.335463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.471219</td>\n",
              "      <td>0.406263</td>\n",
              "      <td>0.570319</td>\n",
              "      <td>0.541971</td>\n",
              "      <td>0.692552</td>\n",
              "      <td>0.386553</td>\n",
              "      <td>0.581683</td>\n",
              "      <td>0.485832</td>\n",
              "      <td>0.650151</td>\n",
              "      <td>0.259935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.006867</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.186868</td>\n",
              "      <td>0.541694</td>\n",
              "      <td>0.535038</td>\n",
              "      <td>0.542487</td>\n",
              "      <td>0.784022</td>\n",
              "      <td>0.441919</td>\n",
              "      <td>0.521529</td>\n",
              "      <td>0.395007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.536447</td>\n",
              "      <td>0.381165</td>\n",
              "      <td>0.566132</td>\n",
              "      <td>0.586573</td>\n",
              "      <td>0.715858</td>\n",
              "      <td>0.419549</td>\n",
              "      <td>0.571692</td>\n",
              "      <td>0.405871</td>\n",
              "      <td>0.651065</td>\n",
              "      <td>0.248055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002747</td>\n",
              "      <td>0.817387</td>\n",
              "      <td>0.261164</td>\n",
              "      <td>0.552048</td>\n",
              "      <td>0.543797</td>\n",
              "      <td>0.550565</td>\n",
              "      <td>0.785926</td>\n",
              "      <td>0.441782</td>\n",
              "      <td>0.501923</td>\n",
              "      <td>0.251173</td>\n",
              "      <td>...</td>\n",
              "      <td>0.650606</td>\n",
              "      <td>0.391680</td>\n",
              "      <td>0.556455</td>\n",
              "      <td>0.465054</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.299797</td>\n",
              "      <td>0.572812</td>\n",
              "      <td>0.508024</td>\n",
              "      <td>0.648075</td>\n",
              "      <td>0.258368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.786132</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>0.568267</td>\n",
              "      <td>0.629324</td>\n",
              "      <td>0.531030</td>\n",
              "      <td>0.803605</td>\n",
              "      <td>0.446723</td>\n",
              "      <td>0.515637</td>\n",
              "      <td>0.236953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.539218</td>\n",
              "      <td>0.385381</td>\n",
              "      <td>0.561330</td>\n",
              "      <td>0.500019</td>\n",
              "      <td>0.703333</td>\n",
              "      <td>0.557150</td>\n",
              "      <td>0.578470</td>\n",
              "      <td>0.423333</td>\n",
              "      <td>0.625833</td>\n",
              "      <td>0.249951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>0.007326</td>\n",
              "      <td>0.798893</td>\n",
              "      <td>0.301278</td>\n",
              "      <td>0.542977</td>\n",
              "      <td>0.549272</td>\n",
              "      <td>0.538444</td>\n",
              "      <td>0.786754</td>\n",
              "      <td>0.474722</td>\n",
              "      <td>0.505937</td>\n",
              "      <td>0.253219</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501090</td>\n",
              "      <td>0.393688</td>\n",
              "      <td>0.564249</td>\n",
              "      <td>0.524623</td>\n",
              "      <td>0.698836</td>\n",
              "      <td>0.305282</td>\n",
              "      <td>0.598338</td>\n",
              "      <td>0.396082</td>\n",
              "      <td>0.651660</td>\n",
              "      <td>0.258256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>0.001272</td>\n",
              "      <td>0.793069</td>\n",
              "      <td>0.157386</td>\n",
              "      <td>0.553693</td>\n",
              "      <td>0.522448</td>\n",
              "      <td>0.551939</td>\n",
              "      <td>0.782272</td>\n",
              "      <td>0.405393</td>\n",
              "      <td>0.507627</td>\n",
              "      <td>0.253134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.592491</td>\n",
              "      <td>0.393279</td>\n",
              "      <td>0.569585</td>\n",
              "      <td>0.573206</td>\n",
              "      <td>0.695802</td>\n",
              "      <td>0.522766</td>\n",
              "      <td>0.601414</td>\n",
              "      <td>0.453475</td>\n",
              "      <td>0.651952</td>\n",
              "      <td>0.259701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.763356</td>\n",
              "      <td>0.170194</td>\n",
              "      <td>0.532351</td>\n",
              "      <td>0.521483</td>\n",
              "      <td>0.534035</td>\n",
              "      <td>0.797997</td>\n",
              "      <td>0.472407</td>\n",
              "      <td>0.488551</td>\n",
              "      <td>0.327849</td>\n",
              "      <td>...</td>\n",
              "      <td>0.732113</td>\n",
              "      <td>0.383653</td>\n",
              "      <td>0.564374</td>\n",
              "      <td>0.503341</td>\n",
              "      <td>0.702928</td>\n",
              "      <td>0.365480</td>\n",
              "      <td>0.550635</td>\n",
              "      <td>0.409866</td>\n",
              "      <td>0.607199</td>\n",
              "      <td>0.249779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.797104</td>\n",
              "      <td>0.193456</td>\n",
              "      <td>0.537817</td>\n",
              "      <td>0.515131</td>\n",
              "      <td>0.545389</td>\n",
              "      <td>0.794162</td>\n",
              "      <td>0.438626</td>\n",
              "      <td>0.493937</td>\n",
              "      <td>0.381195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533268</td>\n",
              "      <td>0.389630</td>\n",
              "      <td>0.560591</td>\n",
              "      <td>0.495147</td>\n",
              "      <td>0.703649</td>\n",
              "      <td>0.496610</td>\n",
              "      <td>0.563382</td>\n",
              "      <td>0.556007</td>\n",
              "      <td>0.653195</td>\n",
              "      <td>0.259131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af9a2ded-ac91-4f82-a20e-932f663a33ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af9a2ded-ac91-4f82-a20e-932f663a33ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af9a2ded-ac91-4f82-a20e-932f663a33ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing some data preprocessing for the testing data. First, converting the data for normalization using Min-Max Scaling between the range of 0\n",
        "# to 1\n",
        "\n",
        "# Create MinMaxScaler object\n",
        "scaler = MinMaxScaler()\n",
        "# apply Min-Max scaling to all columns\n",
        "x_test_normal = pd.DataFrame(scaler.fit_transform(df_xtest), columns=df_xtest.columns)\n",
        "x_test_normal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "1WBQ_MRUutuy",
        "outputId": "4118a36a-c3a2-4d39-b7e1-33557e60109a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            v1        v2        v3        v4        v5        v6        v7  \\\n",
              "0     0.032553  0.910222  0.341189  0.397284  0.647371  0.504942  0.532419   \n",
              "1     0.034228  0.890531  0.286885  0.398539  0.602601  0.513235  0.521178   \n",
              "2     0.171854  0.884603  0.362615  0.377468  0.634545  0.532988  0.521405   \n",
              "3     0.002005  0.928952  0.296896  0.432033  0.579953  0.529831  0.524459   \n",
              "4     0.003580  0.925045  0.250642  0.407319  0.595775  0.524374  0.530432   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9995  0.001333  0.875178  0.287909  0.439126  0.603210  0.537277  0.525038   \n",
              "9996  0.000000  0.931703  0.463406  0.408241  0.667453  0.501681  0.539987   \n",
              "9997  0.004335  0.914797  0.513160  0.431900  0.637301  0.515382  0.538374   \n",
              "9998  0.003579  0.943029  0.210560  0.401206  0.604865  0.506201  0.536501   \n",
              "9999  0.003809  0.824372  0.381882  0.438591  0.610328  0.529416  0.519765   \n",
              "\n",
              "            v8        v9       v10  ...       v18       v19       v20  \\\n",
              "0     0.489454  0.622968  0.443035  ...  0.333376  0.564041  0.365613   \n",
              "1     0.482391  0.603566  0.372894  ...  0.532484  0.583605  0.366454   \n",
              "2     0.571121  0.576548  0.412580  ...  0.558776  0.636231  0.389235   \n",
              "3     0.499241  0.575276  0.302925  ...  0.287863  0.566504  0.369816   \n",
              "4     0.500672  0.587573  0.447844  ...  0.498587  0.559081  0.369583   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "9995  0.513412  0.554192  0.442062  ...  0.514391  0.571897  0.368919   \n",
              "9996  0.546054  0.616490  0.405225  ...  0.407631  0.561088  0.370348   \n",
              "9997  0.430076  0.626076  0.235149  ...  0.428877  0.573408  0.380944   \n",
              "9998  0.461310  0.588910  0.255981  ...  0.519802  0.572194  0.383339   \n",
              "9999  0.522541  0.594735  0.411326  ...  0.529433  0.564536  0.365710   \n",
              "\n",
              "           v21       v22       v23       v24       v25       v26       v27  \n",
              "0     0.541976  0.460346  0.386745  0.463562  0.305064  0.548125  0.354083  \n",
              "1     0.458963  0.465114  0.428242  0.441955  0.246227  0.542683  0.355124  \n",
              "2     0.439946  0.431500  0.456363  0.398166  0.537618  0.522672  0.360552  \n",
              "3     0.528264  0.459218  0.493290  0.454638  0.172260  0.514665  0.344983  \n",
              "4     0.513748  0.463983  0.523188  0.402421  0.497922  0.493534  0.351277  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "9995  0.586838  0.455357  0.528347  0.428859  0.484648  0.571632  0.363160  \n",
              "9996  0.609817  0.464381  0.393939  0.482594  0.405128  0.548942  0.352179  \n",
              "9997  0.631502  0.472501  0.529887  0.297584  0.335882  0.556788  0.356630  \n",
              "9998  0.636585  0.454181  0.418276  0.493944  0.327979  0.537545  0.349612  \n",
              "9999  0.539540  0.464295  0.447980  0.492576  0.237296  0.542491  0.350431  \n",
              "\n",
              "[10000 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69a2aa12-556a-4082-aca6-5d5b63a070cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>...</th>\n",
              "      <th>v18</th>\n",
              "      <th>v19</th>\n",
              "      <th>v20</th>\n",
              "      <th>v21</th>\n",
              "      <th>v22</th>\n",
              "      <th>v23</th>\n",
              "      <th>v24</th>\n",
              "      <th>v25</th>\n",
              "      <th>v26</th>\n",
              "      <th>v27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.032553</td>\n",
              "      <td>0.910222</td>\n",
              "      <td>0.341189</td>\n",
              "      <td>0.397284</td>\n",
              "      <td>0.647371</td>\n",
              "      <td>0.504942</td>\n",
              "      <td>0.532419</td>\n",
              "      <td>0.489454</td>\n",
              "      <td>0.622968</td>\n",
              "      <td>0.443035</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333376</td>\n",
              "      <td>0.564041</td>\n",
              "      <td>0.365613</td>\n",
              "      <td>0.541976</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>0.386745</td>\n",
              "      <td>0.463562</td>\n",
              "      <td>0.305064</td>\n",
              "      <td>0.548125</td>\n",
              "      <td>0.354083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.034228</td>\n",
              "      <td>0.890531</td>\n",
              "      <td>0.286885</td>\n",
              "      <td>0.398539</td>\n",
              "      <td>0.602601</td>\n",
              "      <td>0.513235</td>\n",
              "      <td>0.521178</td>\n",
              "      <td>0.482391</td>\n",
              "      <td>0.603566</td>\n",
              "      <td>0.372894</td>\n",
              "      <td>...</td>\n",
              "      <td>0.532484</td>\n",
              "      <td>0.583605</td>\n",
              "      <td>0.366454</td>\n",
              "      <td>0.458963</td>\n",
              "      <td>0.465114</td>\n",
              "      <td>0.428242</td>\n",
              "      <td>0.441955</td>\n",
              "      <td>0.246227</td>\n",
              "      <td>0.542683</td>\n",
              "      <td>0.355124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.171854</td>\n",
              "      <td>0.884603</td>\n",
              "      <td>0.362615</td>\n",
              "      <td>0.377468</td>\n",
              "      <td>0.634545</td>\n",
              "      <td>0.532988</td>\n",
              "      <td>0.521405</td>\n",
              "      <td>0.571121</td>\n",
              "      <td>0.576548</td>\n",
              "      <td>0.412580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.558776</td>\n",
              "      <td>0.636231</td>\n",
              "      <td>0.389235</td>\n",
              "      <td>0.439946</td>\n",
              "      <td>0.431500</td>\n",
              "      <td>0.456363</td>\n",
              "      <td>0.398166</td>\n",
              "      <td>0.537618</td>\n",
              "      <td>0.522672</td>\n",
              "      <td>0.360552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002005</td>\n",
              "      <td>0.928952</td>\n",
              "      <td>0.296896</td>\n",
              "      <td>0.432033</td>\n",
              "      <td>0.579953</td>\n",
              "      <td>0.529831</td>\n",
              "      <td>0.524459</td>\n",
              "      <td>0.499241</td>\n",
              "      <td>0.575276</td>\n",
              "      <td>0.302925</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287863</td>\n",
              "      <td>0.566504</td>\n",
              "      <td>0.369816</td>\n",
              "      <td>0.528264</td>\n",
              "      <td>0.459218</td>\n",
              "      <td>0.493290</td>\n",
              "      <td>0.454638</td>\n",
              "      <td>0.172260</td>\n",
              "      <td>0.514665</td>\n",
              "      <td>0.344983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.003580</td>\n",
              "      <td>0.925045</td>\n",
              "      <td>0.250642</td>\n",
              "      <td>0.407319</td>\n",
              "      <td>0.595775</td>\n",
              "      <td>0.524374</td>\n",
              "      <td>0.530432</td>\n",
              "      <td>0.500672</td>\n",
              "      <td>0.587573</td>\n",
              "      <td>0.447844</td>\n",
              "      <td>...</td>\n",
              "      <td>0.498587</td>\n",
              "      <td>0.559081</td>\n",
              "      <td>0.369583</td>\n",
              "      <td>0.513748</td>\n",
              "      <td>0.463983</td>\n",
              "      <td>0.523188</td>\n",
              "      <td>0.402421</td>\n",
              "      <td>0.497922</td>\n",
              "      <td>0.493534</td>\n",
              "      <td>0.351277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.001333</td>\n",
              "      <td>0.875178</td>\n",
              "      <td>0.287909</td>\n",
              "      <td>0.439126</td>\n",
              "      <td>0.603210</td>\n",
              "      <td>0.537277</td>\n",
              "      <td>0.525038</td>\n",
              "      <td>0.513412</td>\n",
              "      <td>0.554192</td>\n",
              "      <td>0.442062</td>\n",
              "      <td>...</td>\n",
              "      <td>0.514391</td>\n",
              "      <td>0.571897</td>\n",
              "      <td>0.368919</td>\n",
              "      <td>0.586838</td>\n",
              "      <td>0.455357</td>\n",
              "      <td>0.528347</td>\n",
              "      <td>0.428859</td>\n",
              "      <td>0.484648</td>\n",
              "      <td>0.571632</td>\n",
              "      <td>0.363160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.931703</td>\n",
              "      <td>0.463406</td>\n",
              "      <td>0.408241</td>\n",
              "      <td>0.667453</td>\n",
              "      <td>0.501681</td>\n",
              "      <td>0.539987</td>\n",
              "      <td>0.546054</td>\n",
              "      <td>0.616490</td>\n",
              "      <td>0.405225</td>\n",
              "      <td>...</td>\n",
              "      <td>0.407631</td>\n",
              "      <td>0.561088</td>\n",
              "      <td>0.370348</td>\n",
              "      <td>0.609817</td>\n",
              "      <td>0.464381</td>\n",
              "      <td>0.393939</td>\n",
              "      <td>0.482594</td>\n",
              "      <td>0.405128</td>\n",
              "      <td>0.548942</td>\n",
              "      <td>0.352179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.004335</td>\n",
              "      <td>0.914797</td>\n",
              "      <td>0.513160</td>\n",
              "      <td>0.431900</td>\n",
              "      <td>0.637301</td>\n",
              "      <td>0.515382</td>\n",
              "      <td>0.538374</td>\n",
              "      <td>0.430076</td>\n",
              "      <td>0.626076</td>\n",
              "      <td>0.235149</td>\n",
              "      <td>...</td>\n",
              "      <td>0.428877</td>\n",
              "      <td>0.573408</td>\n",
              "      <td>0.380944</td>\n",
              "      <td>0.631502</td>\n",
              "      <td>0.472501</td>\n",
              "      <td>0.529887</td>\n",
              "      <td>0.297584</td>\n",
              "      <td>0.335882</td>\n",
              "      <td>0.556788</td>\n",
              "      <td>0.356630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.003579</td>\n",
              "      <td>0.943029</td>\n",
              "      <td>0.210560</td>\n",
              "      <td>0.401206</td>\n",
              "      <td>0.604865</td>\n",
              "      <td>0.506201</td>\n",
              "      <td>0.536501</td>\n",
              "      <td>0.461310</td>\n",
              "      <td>0.588910</td>\n",
              "      <td>0.255981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.519802</td>\n",
              "      <td>0.572194</td>\n",
              "      <td>0.383339</td>\n",
              "      <td>0.636585</td>\n",
              "      <td>0.454181</td>\n",
              "      <td>0.418276</td>\n",
              "      <td>0.493944</td>\n",
              "      <td>0.327979</td>\n",
              "      <td>0.537545</td>\n",
              "      <td>0.349612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.003809</td>\n",
              "      <td>0.824372</td>\n",
              "      <td>0.381882</td>\n",
              "      <td>0.438591</td>\n",
              "      <td>0.610328</td>\n",
              "      <td>0.529416</td>\n",
              "      <td>0.519765</td>\n",
              "      <td>0.522541</td>\n",
              "      <td>0.594735</td>\n",
              "      <td>0.411326</td>\n",
              "      <td>...</td>\n",
              "      <td>0.529433</td>\n",
              "      <td>0.564536</td>\n",
              "      <td>0.365710</td>\n",
              "      <td>0.539540</td>\n",
              "      <td>0.464295</td>\n",
              "      <td>0.447980</td>\n",
              "      <td>0.492576</td>\n",
              "      <td>0.237296</td>\n",
              "      <td>0.542491</td>\n",
              "      <td>0.350431</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69a2aa12-556a-4082-aca6-5d5b63a070cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69a2aa12-556a-4082-aca6-5d5b63a070cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69a2aa12-556a-4082-aca6-5d5b63a070cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating some plot to see the data seperation\n",
        "# separate 0 and 1 values into two Series\n",
        "zeros = df_ytrain.loc[df_ytrain['isfraud'] == 0, 'isfraud']\n",
        "ones = df_ytrain.loc[df_ytrain['isfraud'] == 1, 'isfraud']\n",
        "\n",
        "# create scatter plots for 0 and 1 values\n",
        "plt.scatter(range(len(zeros)), zeros, color='blue', marker='o', label='0')\n",
        "plt.scatter(range(len(ones)), ones, color='red', marker='x', label='1')\n",
        "\n",
        "# add axis labels and legend\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend()\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ZYVOjyKGhU-L",
        "outputId": "f633e498-1154-488d-d360-67560d54b194"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now it can be seen that there are much more of 0s than 1s in our data, so it best to reduce the number of 0s to not\n",
        "# have a bias machine learning training data.\n",
        "\n",
        "# Let us first look at the number of 0s and 1s\n",
        "print('The number of 0s are', len(zeros))\n",
        "print('The number of 1s are', len(ones))\n",
        "x_normalized_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "rbkByx3DhWgs",
        "outputId": "7ca9266f-9771-498b-ecac-470ea5bfd229"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of 0s are 199647\n",
            "The number of 1s are 353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              v1        v2        v3        v4        v5        v6        v7  \\\n",
              "0       0.013166  0.768603  0.266142  0.535434  0.522835  0.541423  0.783392   \n",
              "1       0.000228  0.801162  0.242514  0.555572  0.538073  0.549635  0.787447   \n",
              "2       0.031874  0.817670  0.400953  0.527333  0.587932  0.534521  0.793047   \n",
              "3       0.006867  0.818750  0.186868  0.541694  0.535038  0.542487  0.784022   \n",
              "4       0.002747  0.817387  0.261164  0.552048  0.543797  0.550565  0.785926   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "199995  0.001567  0.786132  0.295686  0.568267  0.629324  0.531030  0.803605   \n",
              "199996  0.007326  0.798893  0.301278  0.542977  0.549272  0.538444  0.786754   \n",
              "199997  0.001272  0.793069  0.157386  0.553693  0.522448  0.551939  0.782272   \n",
              "199998  0.000544  0.763356  0.170194  0.532351  0.521483  0.534035  0.797997   \n",
              "199999  0.001475  0.797104  0.193456  0.537817  0.515131  0.545389  0.794162   \n",
              "\n",
              "              v8        v9       v10  ...       v18       v19       v20  \\\n",
              "0       0.501795  0.502335  0.268482  ...  0.544884  0.395308  0.561678   \n",
              "1       0.457165  0.497903  0.234985  ...  0.558398  0.390898  0.556413   \n",
              "2       0.490613  0.509299  0.335463  ...  0.471219  0.406263  0.570319   \n",
              "3       0.441919  0.521529  0.395007  ...  0.536447  0.381165  0.566132   \n",
              "4       0.441782  0.501923  0.251173  ...  0.650606  0.391680  0.556455   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "199995  0.446723  0.515637  0.236953  ...  0.539218  0.385381  0.561330   \n",
              "199996  0.474722  0.505937  0.253219  ...  0.501090  0.393688  0.564249   \n",
              "199997  0.405393  0.507627  0.253134  ...  0.592491  0.393279  0.569585   \n",
              "199998  0.472407  0.488551  0.327849  ...  0.732113  0.383653  0.564374   \n",
              "199999  0.438626  0.493937  0.381195  ...  0.533268  0.389630  0.560591   \n",
              "\n",
              "             v21       v22       v23       v24       v25       v26       v27  \n",
              "0       0.491362  0.704808  0.411224  0.543566  0.395226  0.648976  0.257249  \n",
              "1       0.470343  0.700732  0.265424  0.570273  0.475939  0.657261  0.258859  \n",
              "2       0.541971  0.692552  0.386553  0.581683  0.485832  0.650151  0.259935  \n",
              "3       0.586573  0.715858  0.419549  0.571692  0.405871  0.651065  0.248055  \n",
              "4       0.465054  0.700437  0.299797  0.572812  0.508024  0.648075  0.258368  \n",
              "...          ...       ...       ...       ...       ...       ...       ...  \n",
              "199995  0.500019  0.703333  0.557150  0.578470  0.423333  0.625833  0.249951  \n",
              "199996  0.524623  0.698836  0.305282  0.598338  0.396082  0.651660  0.258256  \n",
              "199997  0.573206  0.695802  0.522766  0.601414  0.453475  0.651952  0.259701  \n",
              "199998  0.503341  0.702928  0.365480  0.550635  0.409866  0.607199  0.249779  \n",
              "199999  0.495147  0.703649  0.496610  0.563382  0.556007  0.653195  0.259131  \n",
              "\n",
              "[200000 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e1e826d-f74a-48d6-9e63-0f041405c334\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>...</th>\n",
              "      <th>v18</th>\n",
              "      <th>v19</th>\n",
              "      <th>v20</th>\n",
              "      <th>v21</th>\n",
              "      <th>v22</th>\n",
              "      <th>v23</th>\n",
              "      <th>v24</th>\n",
              "      <th>v25</th>\n",
              "      <th>v26</th>\n",
              "      <th>v27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013166</td>\n",
              "      <td>0.768603</td>\n",
              "      <td>0.266142</td>\n",
              "      <td>0.535434</td>\n",
              "      <td>0.522835</td>\n",
              "      <td>0.541423</td>\n",
              "      <td>0.783392</td>\n",
              "      <td>0.501795</td>\n",
              "      <td>0.502335</td>\n",
              "      <td>0.268482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.544884</td>\n",
              "      <td>0.395308</td>\n",
              "      <td>0.561678</td>\n",
              "      <td>0.491362</td>\n",
              "      <td>0.704808</td>\n",
              "      <td>0.411224</td>\n",
              "      <td>0.543566</td>\n",
              "      <td>0.395226</td>\n",
              "      <td>0.648976</td>\n",
              "      <td>0.257249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.801162</td>\n",
              "      <td>0.242514</td>\n",
              "      <td>0.555572</td>\n",
              "      <td>0.538073</td>\n",
              "      <td>0.549635</td>\n",
              "      <td>0.787447</td>\n",
              "      <td>0.457165</td>\n",
              "      <td>0.497903</td>\n",
              "      <td>0.234985</td>\n",
              "      <td>...</td>\n",
              "      <td>0.558398</td>\n",
              "      <td>0.390898</td>\n",
              "      <td>0.556413</td>\n",
              "      <td>0.470343</td>\n",
              "      <td>0.700732</td>\n",
              "      <td>0.265424</td>\n",
              "      <td>0.570273</td>\n",
              "      <td>0.475939</td>\n",
              "      <td>0.657261</td>\n",
              "      <td>0.258859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.031874</td>\n",
              "      <td>0.817670</td>\n",
              "      <td>0.400953</td>\n",
              "      <td>0.527333</td>\n",
              "      <td>0.587932</td>\n",
              "      <td>0.534521</td>\n",
              "      <td>0.793047</td>\n",
              "      <td>0.490613</td>\n",
              "      <td>0.509299</td>\n",
              "      <td>0.335463</td>\n",
              "      <td>...</td>\n",
              "      <td>0.471219</td>\n",
              "      <td>0.406263</td>\n",
              "      <td>0.570319</td>\n",
              "      <td>0.541971</td>\n",
              "      <td>0.692552</td>\n",
              "      <td>0.386553</td>\n",
              "      <td>0.581683</td>\n",
              "      <td>0.485832</td>\n",
              "      <td>0.650151</td>\n",
              "      <td>0.259935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.006867</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.186868</td>\n",
              "      <td>0.541694</td>\n",
              "      <td>0.535038</td>\n",
              "      <td>0.542487</td>\n",
              "      <td>0.784022</td>\n",
              "      <td>0.441919</td>\n",
              "      <td>0.521529</td>\n",
              "      <td>0.395007</td>\n",
              "      <td>...</td>\n",
              "      <td>0.536447</td>\n",
              "      <td>0.381165</td>\n",
              "      <td>0.566132</td>\n",
              "      <td>0.586573</td>\n",
              "      <td>0.715858</td>\n",
              "      <td>0.419549</td>\n",
              "      <td>0.571692</td>\n",
              "      <td>0.405871</td>\n",
              "      <td>0.651065</td>\n",
              "      <td>0.248055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002747</td>\n",
              "      <td>0.817387</td>\n",
              "      <td>0.261164</td>\n",
              "      <td>0.552048</td>\n",
              "      <td>0.543797</td>\n",
              "      <td>0.550565</td>\n",
              "      <td>0.785926</td>\n",
              "      <td>0.441782</td>\n",
              "      <td>0.501923</td>\n",
              "      <td>0.251173</td>\n",
              "      <td>...</td>\n",
              "      <td>0.650606</td>\n",
              "      <td>0.391680</td>\n",
              "      <td>0.556455</td>\n",
              "      <td>0.465054</td>\n",
              "      <td>0.700437</td>\n",
              "      <td>0.299797</td>\n",
              "      <td>0.572812</td>\n",
              "      <td>0.508024</td>\n",
              "      <td>0.648075</td>\n",
              "      <td>0.258368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.786132</td>\n",
              "      <td>0.295686</td>\n",
              "      <td>0.568267</td>\n",
              "      <td>0.629324</td>\n",
              "      <td>0.531030</td>\n",
              "      <td>0.803605</td>\n",
              "      <td>0.446723</td>\n",
              "      <td>0.515637</td>\n",
              "      <td>0.236953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.539218</td>\n",
              "      <td>0.385381</td>\n",
              "      <td>0.561330</td>\n",
              "      <td>0.500019</td>\n",
              "      <td>0.703333</td>\n",
              "      <td>0.557150</td>\n",
              "      <td>0.578470</td>\n",
              "      <td>0.423333</td>\n",
              "      <td>0.625833</td>\n",
              "      <td>0.249951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>0.007326</td>\n",
              "      <td>0.798893</td>\n",
              "      <td>0.301278</td>\n",
              "      <td>0.542977</td>\n",
              "      <td>0.549272</td>\n",
              "      <td>0.538444</td>\n",
              "      <td>0.786754</td>\n",
              "      <td>0.474722</td>\n",
              "      <td>0.505937</td>\n",
              "      <td>0.253219</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501090</td>\n",
              "      <td>0.393688</td>\n",
              "      <td>0.564249</td>\n",
              "      <td>0.524623</td>\n",
              "      <td>0.698836</td>\n",
              "      <td>0.305282</td>\n",
              "      <td>0.598338</td>\n",
              "      <td>0.396082</td>\n",
              "      <td>0.651660</td>\n",
              "      <td>0.258256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>0.001272</td>\n",
              "      <td>0.793069</td>\n",
              "      <td>0.157386</td>\n",
              "      <td>0.553693</td>\n",
              "      <td>0.522448</td>\n",
              "      <td>0.551939</td>\n",
              "      <td>0.782272</td>\n",
              "      <td>0.405393</td>\n",
              "      <td>0.507627</td>\n",
              "      <td>0.253134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.592491</td>\n",
              "      <td>0.393279</td>\n",
              "      <td>0.569585</td>\n",
              "      <td>0.573206</td>\n",
              "      <td>0.695802</td>\n",
              "      <td>0.522766</td>\n",
              "      <td>0.601414</td>\n",
              "      <td>0.453475</td>\n",
              "      <td>0.651952</td>\n",
              "      <td>0.259701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.763356</td>\n",
              "      <td>0.170194</td>\n",
              "      <td>0.532351</td>\n",
              "      <td>0.521483</td>\n",
              "      <td>0.534035</td>\n",
              "      <td>0.797997</td>\n",
              "      <td>0.472407</td>\n",
              "      <td>0.488551</td>\n",
              "      <td>0.327849</td>\n",
              "      <td>...</td>\n",
              "      <td>0.732113</td>\n",
              "      <td>0.383653</td>\n",
              "      <td>0.564374</td>\n",
              "      <td>0.503341</td>\n",
              "      <td>0.702928</td>\n",
              "      <td>0.365480</td>\n",
              "      <td>0.550635</td>\n",
              "      <td>0.409866</td>\n",
              "      <td>0.607199</td>\n",
              "      <td>0.249779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.797104</td>\n",
              "      <td>0.193456</td>\n",
              "      <td>0.537817</td>\n",
              "      <td>0.515131</td>\n",
              "      <td>0.545389</td>\n",
              "      <td>0.794162</td>\n",
              "      <td>0.438626</td>\n",
              "      <td>0.493937</td>\n",
              "      <td>0.381195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.533268</td>\n",
              "      <td>0.389630</td>\n",
              "      <td>0.560591</td>\n",
              "      <td>0.495147</td>\n",
              "      <td>0.703649</td>\n",
              "      <td>0.496610</td>\n",
              "      <td>0.563382</td>\n",
              "      <td>0.556007</td>\n",
              "      <td>0.653195</td>\n",
              "      <td>0.259131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e1e826d-f74a-48d6-9e63-0f041405c334')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e1e826d-f74a-48d6-9e63-0f041405c334 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e1e826d-f74a-48d6-9e63-0f041405c334');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It is best to make the data balance. I will be using the Synthetic minority over-sampling technique. It will allow\n",
        "# to handle class imbalance. It involves generating synthetic samples for minority class using interpolation. \n",
        "\n",
        "# perform SMOTE over-sampling\n",
        "smote = SMOTE()\n",
        "x_resampled, y_resampled = smote.fit_resample(x_normalized_data, df_ytrain)\n",
        "\n",
        "# print the number of samples in each class\n",
        "print('The shape of features is', x_resampled.shape)\n",
        "print('The shape of label is', y_resampled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW6rhzsphYU0",
        "outputId": "6f36df9a-ea56-4771-ac5f-792e8eb8580b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of features is (399294, 27)\n",
            "The shape of label is (399294, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us now look at the samples and see the visualization\n",
        "# Creating some plot to see the data seperation\n",
        "# separate 0 and 1 values into two Series\n",
        "zeros = y_resampled.loc[y_resampled['isfraud'] == 0, 'isfraud']\n",
        "ones = y_resampled.loc[y_resampled['isfraud'] == 1, 'isfraud']\n",
        "\n",
        "# create scatter plots for 0 and 1 values\n",
        "plt.scatter(range(len(zeros)), zeros, color='blue', marker='o', label='0')\n",
        "plt.scatter(range(len(ones)), ones, color='red', marker='x', label='1')\n",
        "\n",
        "# add axis labels and legend\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Feature Value')\n",
        "plt.legend()\n",
        "\n",
        "# show plot\n",
        "plt.show()\n",
        "print('The number of 0s in the new balanced data is', len(zeros))\n",
        "print('The number of 1s in the new balanced data is', len(ones))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "VYhxzZ3khbFQ",
        "outputId": "9d7268fa-6350-4f57-fc43-63189b7dcfaf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of 0s in the new balanced data is 199647\n",
            "The number of 1s in the new balanced data is 199647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the training data.\n",
        "xtrain = x_resampled.to_numpy()\n",
        "ytrain = y_resampled.to_numpy()\n",
        "xtest = x_test_normal.to_numpy()\n",
        "ytrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCYi6OyshcuY",
        "outputId": "f3fa2da5-1015-409a-ccac-468d699ab281"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(399294, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output target (y) - it is a binary 0/1 variable.\n",
        "# So you can use sigmoid activation\n",
        "y = ytrain\n",
        "# input - 27 variables (columns)\n",
        "x = xtrain\n",
        "\n",
        "# number of input rows\n",
        "nrows = xtrain.shape[0]\n",
        "# number of columns\n",
        "ncols = xtrain.shape[1]\n",
        "\n",
        "print(nrows,ncols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yocgYSAdorsF",
        "outputId": "0366b43e-5c2f-44dd-abfd-4a8d6a1684b6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "399294 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_split_train_test(features, label, train_perc=.8, random_state=42):\n",
        "    \"\"\"\n",
        "    Shuffle the features and labels so they are in a random order.\n",
        "        sklearn.utils.shuffle does this well.\n",
        "    Then split the features and labels into training and testing sets\n",
        "        where train_perc of the samples are in training and the\n",
        "        remaining are for testing.\n",
        "    \"\"\"\n",
        "    #features_shuffles, label_shuffle = shuffle(features, label, random_state=42)\n",
        "    test_size = 1 - train_perc\n",
        "    features_tr, features_te, label_tr, label_te = train_test_split(features, label, \n",
        "                                                                     train_size=train_perc,\n",
        "                                                                     shuffle=True,\n",
        "                                                                     random_state=random_state,\n",
        "                                                                     stratify=label)\n",
        "    \n",
        "    return features_tr, features_te, label_tr, label_te"
      ],
      "metadata": {
        "id": "C66Ygz8rpmYB"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data between 80% training and 20% testing for getting the score\n",
        "x_train, x_test, y_train, y_test = rand_split_train_test(x, y)"
      ],
      "metadata": {
        "id": "HDTZbEFDpAwl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the model to the training data\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "# evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-ZtF_s8pwx2",
        "outputId": "22296580-05d7-4f68-df54-9274d70af7cd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "9983/9983 [==============================] - 29s 3ms/step - loss: 0.1797 - accuracy: 0.9292\n",
            "Epoch 2/20\n",
            "9983/9983 [==============================] - 31s 3ms/step - loss: 0.1501 - accuracy: 0.9404\n",
            "Epoch 3/20\n",
            "9983/9983 [==============================] - 30s 3ms/step - loss: 0.1369 - accuracy: 0.9453\n",
            "Epoch 4/20\n",
            "9983/9983 [==============================] - 31s 3ms/step - loss: 0.1259 - accuracy: 0.9493\n",
            "Epoch 5/20\n",
            "9983/9983 [==============================] - 30s 3ms/step - loss: 0.1146 - accuracy: 0.9530\n",
            "Epoch 6/20\n",
            "9983/9983 [==============================] - 28s 3ms/step - loss: 0.1067 - accuracy: 0.9555\n",
            "Epoch 7/20\n",
            "9983/9983 [==============================] - 26s 3ms/step - loss: 0.1006 - accuracy: 0.9577\n",
            "Epoch 8/20\n",
            "9983/9983 [==============================] - 27s 3ms/step - loss: 0.0932 - accuracy: 0.9606\n",
            "Epoch 9/20\n",
            "9983/9983 [==============================] - 30s 3ms/step - loss: 0.0873 - accuracy: 0.9632\n",
            "Epoch 10/20\n",
            "9983/9983 [==============================] - 36s 4ms/step - loss: 0.0816 - accuracy: 0.9656\n",
            "Epoch 11/20\n",
            "9983/9983 [==============================] - 29s 3ms/step - loss: 0.0751 - accuracy: 0.9688\n",
            "Epoch 12/20\n",
            "9983/9983 [==============================] - 22s 2ms/step - loss: 0.0689 - accuracy: 0.9712\n",
            "Epoch 13/20\n",
            "9983/9983 [==============================] - 23s 2ms/step - loss: 0.0643 - accuracy: 0.9734\n",
            "Epoch 14/20\n",
            "9983/9983 [==============================] - 21s 2ms/step - loss: 0.0597 - accuracy: 0.9759\n",
            "Epoch 15/20\n",
            "9983/9983 [==============================] - 22s 2ms/step - loss: 0.0571 - accuracy: 0.9774\n",
            "Epoch 16/20\n",
            "9983/9983 [==============================] - 23s 2ms/step - loss: 0.0537 - accuracy: 0.9788\n",
            "Epoch 17/20\n",
            "9983/9983 [==============================] - 23s 2ms/step - loss: 0.0518 - accuracy: 0.9799\n",
            "Epoch 18/20\n",
            "9983/9983 [==============================] - 21s 2ms/step - loss: 0.0499 - accuracy: 0.9809\n",
            "Epoch 19/20\n",
            "9983/9983 [==============================] - 25s 3ms/step - loss: 0.0463 - accuracy: 0.9824\n",
            "Epoch 20/20\n",
            "9983/9983 [==============================] - 21s 2ms/step - loss: 0.0449 - accuracy: 0.9832\n",
            "2496/2496 [==============================] - 6s 2ms/step - loss: 0.0415 - accuracy: 0.9848\n",
            "Test accuracy: 0.9848107099533081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make class predictions with the model\n",
        "ytest_prediction = model.predict(x_test)\n",
        "# round it to make is either 0 or 1\n",
        "ytest = np.round(ytest_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrztDpPpqqfS",
        "outputId": "4a02de2a-9a29-4957-c688-81a7d41f05ac"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2496/2496 [==============================] - 4s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get its accuracy using sklearn classification report\n",
        "print(classification_report(y_test, ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdMDjU6srAjJ",
        "outputId": "be5efa8c-eded-4fda-e203-a6143b50d474"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98     39930\n",
            "           1       0.98      0.99      0.98     39929\n",
            "\n",
            "    accuracy                           0.98     79859\n",
            "   macro avg       0.98      0.98      0.98     79859\n",
            "weighted avg       0.98      0.98      0.98     79859\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Matthews Correlation Coefficient using sklearn matthews_corrcoef\n",
        "print(round(matthews_corrcoef(y_test, ytest), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vGNxFF_rM5B",
        "outputId": "a57738d8-4b1d-4679-af54-10581d121060"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it can be seen that we have a good Matthews Correlation using the model that we had, therefore, we can now train our whole model on the entire dataset without splitting it for training and testing and then storing the output in csv file"
      ],
      "metadata": {
        "id": "qGJQd_aDsO1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(xtrain.shape[1],)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "final_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the model to the training data\n",
        "final_model.fit(xtrain, ytrain, epochs=20, batch_size=32)\n",
        "\n",
        "# evaluate the model on the test data\n",
        "loss, accuracy = final_model.evaluate(xtrain, ytrain)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "NJfv4cP2h8LW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4f6814-7a19-4e65-f40f-1905eda8f340"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12478/12478 [==============================] - 30s 2ms/step - loss: 0.1754 - accuracy: 0.9315\n",
            "Epoch 2/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.1340 - accuracy: 0.9469\n",
            "Epoch 3/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.1183 - accuracy: 0.9530\n",
            "Epoch 4/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.1087 - accuracy: 0.9567\n",
            "Epoch 5/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.1010 - accuracy: 0.9592\n",
            "Epoch 6/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.0926 - accuracy: 0.9621\n",
            "Epoch 7/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.0850 - accuracy: 0.9645\n",
            "Epoch 8/20\n",
            "12478/12478 [==============================] - 30s 2ms/step - loss: 0.0792 - accuracy: 0.9665\n",
            "Epoch 9/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0733 - accuracy: 0.9689\n",
            "Epoch 10/20\n",
            "12478/12478 [==============================] - 27s 2ms/step - loss: 0.0699 - accuracy: 0.9709\n",
            "Epoch 11/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0652 - accuracy: 0.9729\n",
            "Epoch 12/20\n",
            "12478/12478 [==============================] - 36s 3ms/step - loss: 0.0617 - accuracy: 0.9752\n",
            "Epoch 13/20\n",
            "12478/12478 [==============================] - 32s 3ms/step - loss: 0.0579 - accuracy: 0.9775\n",
            "Epoch 14/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0546 - accuracy: 0.9790\n",
            "Epoch 15/20\n",
            "12478/12478 [==============================] - 30s 2ms/step - loss: 0.0520 - accuracy: 0.9803\n",
            "Epoch 16/20\n",
            "12478/12478 [==============================] - 29s 2ms/step - loss: 0.0493 - accuracy: 0.9817\n",
            "Epoch 17/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0474 - accuracy: 0.9827\n",
            "Epoch 18/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0462 - accuracy: 0.9831\n",
            "Epoch 19/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0444 - accuracy: 0.9839\n",
            "Epoch 20/20\n",
            "12478/12478 [==============================] - 28s 2ms/step - loss: 0.0428 - accuracy: 0.9846\n",
            "12478/12478 [==============================] - 22s 2ms/step - loss: 0.0348 - accuracy: 0.9891\n",
            "Test accuracy: 0.9890556931495667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make class predictions with the model\n",
        "ytest_prediction = model.predict(xtest)\n",
        "# round it to make is either 0 or 1\n",
        "ytest = np.round(ytest_prediction)\n",
        "ytest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3GpvnhCw1A8",
        "outputId": "6453ed8e-9a20-46b7-9291-891fab46e840"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test row numbers\n",
        "ytest_id = np.arange(1,xtest.shape[0]+1)\n",
        "ytest_id = np.reshape(ytest_id,(xtest.shape[0],1))\n",
        "# combine y_test row numbers & prediction\n",
        "data = np.concatenate((ytest_id,ytest),axis=1)\n",
        "dff = pd.DataFrame(data,columns=['id','isfraud'])"
      ],
      "metadata": {
        "id": "P-TUcKVYw63k"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save on Local Drive - it will be on C drive \"Download\" folder\n",
        "# CHANGE FILE NAME to YOUR LastName & FirstName\n",
        "from google.colab import files\n",
        "\n",
        "dff.to_csv('FI424_Competition_ytest_Bajaj_Rajaditya.csv',index=False) \n",
        "files.download('FI424_Competition_ytest_Bajaj_Rajaditya.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T0mGd6u8w9ou",
        "outputId": "559727f8-b2f4-4478-ba0c-667aa255568a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e9b2c918-e681-4560-b752-33118308c12d\", \"FI424_Competition_ytest_Bajaj_Rajaditya.csv\", 108905)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jcGgzave2HX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}